{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LQp47ajD2Ga4"
   },
   "source": [
    "# Знакомство с word2vec\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c_Pat15ls9N8"
   },
   "source": [
    "## Загрузка модели\n",
    "Скачаем модель <code>google-news-vectors</code>. Откроем ее с помощью библиотеки <code>gensim</code>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "nd-xNyAGy1tT",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1687296290449,
     "user_tz": -180,
     "elapsed": 208797,
     "user": {
      "displayName": "Данила Власов",
      "userId": "10847520665763514044"
     }
    },
    "outputId": "5697172d-3bf5-4dfc-ed99-1cd7bbcd0d0a"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m23.4/23.4 MB\u001B[0m \u001B[31m64.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25h  Preparing metadata (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "  \u001B[1;31merror\u001B[0m: \u001B[1msubprocess-exited-with-error\u001B[0m\n",
      "  \n",
      "  \u001B[31m×\u001B[0m \u001B[32mpython setup.py bdist_wheel\u001B[0m did not run successfully.\n",
      "  \u001B[31m│\u001B[0m exit code: \u001B[1;36m1\u001B[0m\n",
      "  \u001B[31m╰─>\u001B[0m See above for output.\n",
      "  \n",
      "  \u001B[1;35mnote\u001B[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  Building wheel for gensim (setup.py) ... \u001B[?25lerror\n",
      "\u001B[31m  ERROR: Failed building wheel for gensim\u001B[0m\u001B[31m\n",
      "\u001B[0m\u001B[31mERROR: Could not build wheels for gensim, which is required to install pyproject.toml-based projects\u001B[0m\u001B[31m\n",
      "\u001B[0m\u001B[?25h/usr/local/lib/python3.10/dist-packages/gdown/cli.py:121: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
      "  warnings.warn(\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=0B7XkCwpI5KDYNlNUTTlSS21pQmM\n",
      "To: /content/GoogleNews-vectors-negative300.bin.gz\n",
      "100% 1.65G/1.65G [00:22<00:00, 72.9MB/s]\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m25.2/25.2 MB\u001B[0m \u001B[31m54.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25h  \u001B[1;31merror\u001B[0m: \u001B[1msubprocess-exited-with-error\u001B[0m\n",
      "  \n",
      "  \u001B[31m×\u001B[0m \u001B[32mpip subprocess to install build dependencies\u001B[0m did not run successfully.\n",
      "  \u001B[31m│\u001B[0m exit code: \u001B[1;36m1\u001B[0m\n",
      "  \u001B[31m╰─>\u001B[0m See above for output.\n",
      "  \n",
      "  \u001B[1;35mnote\u001B[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  Installing build dependencies ... \u001B[?25l\u001B[?25herror\n",
      "\u001B[1;31merror\u001B[0m: \u001B[1msubprocess-exited-with-error\u001B[0m\n",
      "\n",
      "\u001B[31m×\u001B[0m \u001B[32mpip subprocess to install build dependencies\u001B[0m did not run successfully.\n",
      "\u001B[31m│\u001B[0m exit code: \u001B[1;36m1\u001B[0m\n",
      "\u001B[31m╰─>\u001B[0m See above for output.\n",
      "\n",
      "\u001B[1;35mnote\u001B[0m: This error originates from a subprocess, and is likely not a problem with pip.\n"
     ]
    }
   ],
   "source": [
    "! pip install -q -U gensim==3.8.3\n",
    "! gdown --id 0B7XkCwpI5KDYNlNUTTlSS21pQmM\n",
    "! pip install -q SciPy==1.5.4"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "! gunzip GoogleNews-vectors-negative300.bin.gz"
   ],
   "metadata": {
    "id": "t9CnRiM9kL8Q",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1687296341370,
     "user_tz": -180,
     "elapsed": 50927,
     "user": {
      "displayName": "Данила Власов",
      "userId": "10847520665763514044"
     }
    }
   },
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "-4xfcycMynhZ",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1687296383626,
     "user_tz": -180,
     "elapsed": 42261,
     "user": {
      "displayName": "Данила Власов",
      "userId": "10847520665763514044"
     }
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import gensim\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "w = KeyedVectors.load_word2vec_format(\"GoogleNews-vectors-negative300.bin\",\n",
    "                                      binary=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O6JtQjaORfzA"
   },
   "source": [
    "Структура называется <code>KeyedVectors</code> и по сути представляет собой отображение между ключами и векторами. Каждый вектор идентифицируется своим ключом поиска, чаще всего коротким строковым токеном, поэтому обычно это соответствие между\n",
    "\n",
    "<center><code>{str => 1D numpy array}</code></center><br/>\n",
    "\n",
    "\n",
    "\n",
    "Например, выведем первые 10 координат вектора, соответствующего слову <code>sunrise</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ol9DuE6VRfzH",
    "outputId": "3ea46f98-ceaa-48db-d1bb-c01afe00216d",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1687296383627,
     "user_tz": -180,
     "elapsed": 5,
     "user": {
      "displayName": "Данила Власов",
      "userId": "10847520665763514044"
     }
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Размерность вектора:  (300,)\n",
      "Первые 10 координат вектора: \n",
      " [-0.22558594 -0.03540039 -0.21679688  0.03613281 -0.2265625  -0.09814453\n",
      "  0.109375   -0.34570312  0.18652344  0.01806641]\n"
     ]
    }
   ],
   "source": [
    "print(\"Размерность вектора: \", w[\"sunrise\"].shape)\n",
    "print(\"Первые 10 координат вектора: \\n\", w[\"sunrise\"][:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5rv9Rqvq2af8"
   },
   "source": [
    "## Задание 1. Сходство."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mns8gpJFRfzd"
   },
   "source": [
    "Извлеките векторы слов <code>London</code>, <code>England</code>, <code>Moscow</code>. Посчитайте косинусное расстояние между словами <code>London</code> и <code>England</code> и между словами <code>Moscow</code> и <code>England</code>. Какая пара слов ближе? Подсказка: для вычисления косинусного расстояния использвется метод <code>distance()</code>. Правильный ответ представлен в блоке вывода."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s9IrMkVi3Crm",
    "outputId": "f9cd089a-3aaf-45ea-c77a-02321f6451aa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "London = > England:  0.5600714385509491\n",
      "Moscow = > England:  0.8476868271827698\n"
     ]
    }
   ],
   "source": [
    "#enter your code here"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Извлечение векторов слов\n",
    "london_vector = w[\"London\"]\n",
    "england_vector = w[\"England\"]\n",
    "moscow_vector = w[\"Moscow\"]\n",
    "\n",
    "# Вычисление косинусного расстояния\n",
    "london_england_distance = w.distance(\"London\", \"England\")\n",
    "moscow_england_distance = w.distance(\"Moscow\", \"England\")\n",
    "\n",
    "# Вывод результатов\n",
    "print(\"Косинусное расстояние между London и England:\", london_england_distance)\n",
    "print(\"Косинусное расстояние между Moscow и England:\", moscow_england_distance)\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0FA61dSQtfu-",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1687296579068,
     "user_tz": -180,
     "elapsed": 869,
     "user": {
      "displayName": "Данила Власов",
      "userId": "10847520665763514044"
     }
    },
    "outputId": "def967c2-18a3-4c93-ddb9-b3aae7d1812c"
   },
   "execution_count": 6,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Косинусное расстояние между London и England: 0.5600714385509491\n",
      "Косинусное расстояние между Moscow и England: 0.8476868271827698\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nLXEcSxt3DG4"
   },
   "source": [
    "## Задание 2. Аналогии.\n",
    "С помощью метода most_similar решите аналогию\n",
    "```London : England = Moscow : X```\n",
    "\n",
    "Правильный ответ представлен в блоке вывода.\n",
    "\n",
    "(Подсказка: нужно использовать аргументы positive и negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n4Pqub5c3DV8",
    "outputId": "531c98dd-bd64-4989-c493-34d071231eac"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Russia', 0.6502717733383179),\n",
       " ('Ukraine', 0.5879061818122864),\n",
       " ('Belarus', 0.5666375756263733),\n",
       " ('Azerbaijan', 0.5418694019317627),\n",
       " ('Armenia', 0.5300518870353699),\n",
       " ('Poland', 0.525324821472168),\n",
       " ('coach_Georgy_Yartsev', 0.5220180749893188),\n",
       " ('Russian', 0.5214669108390808),\n",
       " ('Croatia', 0.5166041851043701),\n",
       " ('Moldova', 0.5125792026519775)]"
      ]
     },
     "execution_count": 22,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#enter your code here"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Решение аналогии\n",
    "analogy_result = w.most_similar(positive=[\"Moscow\", \"England\"], negative=[\"London\"], topn=1)\n",
    "\n",
    "# Извлечение слова X из результата\n",
    "x_word = analogy_result[0][0]\n",
    "\n",
    "# Вывод результата\n",
    "print(\"Ответ на аналогию Moscow : X = London : England:\", x_word)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FeIFKGBNtuR3",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1687296652236,
     "user_tz": -180,
     "elapsed": 19317,
     "user": {
      "displayName": "Данила Власов",
      "userId": "10847520665763514044"
     }
    },
    "outputId": "c7a5592e-ac05-40ab-8532-efba9df8f09d"
   },
   "execution_count": 8,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Ответ на аналогию Moscow : X = London : England: Russia\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dFzneqrn3Djq"
   },
   "source": [
    "## Задание 3. Сходство: найти лишнее.\n",
    "С помощью метода <code>doesnt_match</code> найдите лишнее слово в ряду <code>breakfast cereal dinner lunch</code>.\n",
    "\n",
    "Правильный ответ представлен в блоке вывода."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "493uH-D33DxJ",
    "outputId": "6b772f13-8f7d-4c3a-ca46-ca29b0d8f85f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лишнее слово:  cereal\n"
     ]
    }
   ],
   "source": [
    "#enter your code here"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Поиск лишнего слова\n",
    "words = [\"breakfast\", \"cereal\", \"dinner\", \"lunch\"]\n",
    "odd_word = w.doesnt_match(words)\n",
    "\n",
    "# Вывод результата\n",
    "print(\"Лишнее слово в ряду 'breakfast cereal dinner lunch':\", odd_word)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IQoLaoweuZM7",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1687298240667,
     "user_tz": -180,
     "elapsed": 21,
     "user": {
      "displayName": "Данила Власов",
      "userId": "10847520665763514044"
     }
    },
    "outputId": "c1789a87-0bbb-47ba-df1f-f4ec334133be"
   },
   "execution_count": 12,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Лишнее слово в ряду 'breakfast cereal dinner lunch': cereal\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BT-Zl3YaRf0X"
   },
   "source": [
    "## Задание 4. Представление предложений в виде векторов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dm_SiyjU3D9G"
   },
   "source": [
    "\n",
    "Дано предложение: <code>the quick brown fox jumps over the lazy dog</code>. Вам нужно представить это предложение в виде вектора. Для этого найдите вектор каждого слова в модели, а затем усредните векторы покомпонентно.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8FbM9gOT3Ofg",
    "outputId": "6f3994b8-353d-475b-f381-17084a765d46"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Первые 5 координат вектора-предложения: [ 0.09055582  0.05434163 -0.06713867  0.10968696 -0.01060655]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "#enter your code here"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "\n",
    "# Предложение\n",
    "sentence = \"the quick brown fox jumps over the lazy dog\"\n",
    "\n",
    "# Разделение предложения на отдельные слова\n",
    "words = sentence.split()\n",
    "\n",
    "# Нахождение вектора каждого слова и добавление в список\n",
    "word_vectors = [w[word] for word in words]\n",
    "\n",
    "# Усреднение векторов\n",
    "sentence_vector = np.mean(word_vectors, axis=0)\n",
    "\n",
    "# Вывод результата\n",
    "print(\"Вектор предложения:\", sentence_vector)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v5VuBz-Lu_Ql",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1687298240668,
     "user_tz": -180,
     "elapsed": 17,
     "user": {
      "displayName": "Данила Власов",
      "userId": "10847520665763514044"
     }
    },
    "outputId": "0e614364-002a-4e3a-d651-3f547ebcbb7b"
   },
   "execution_count": 13,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Вектор предложения: [ 9.05558243e-02  5.43416329e-02 -6.71386719e-02  1.09686956e-01\n",
      " -1.06065534e-02 -1.21066622e-01  4.63748500e-02 -5.35685234e-02\n",
      "  7.00683594e-02  9.72764790e-02  2.70589199e-02 -1.16495766e-01\n",
      "  3.48307304e-02 -2.13351771e-02 -8.32519531e-02 -2.97851562e-02\n",
      " -3.11482754e-02  1.02077909e-01 -7.70467147e-02 -1.05170354e-01\n",
      " -8.54492188e-04  6.69555664e-02  1.97482631e-02  7.00336043e-03\n",
      "  1.32700605e-02  2.12593079e-02 -1.07652456e-01  1.05970591e-01\n",
      "  1.06550425e-01  4.36740462e-03 -5.31684011e-02  6.63248673e-02\n",
      "  3.62277552e-02 -6.70505092e-02 -2.00195312e-02 -1.75272617e-02\n",
      " -2.21082903e-02  6.37478312e-04  9.91753489e-02  1.46647140e-01\n",
      "  9.37500000e-02 -1.67263448e-01  1.36345759e-01 -1.23155378e-02\n",
      "  5.61930351e-02 -6.90680593e-02 -5.95092773e-03 -5.62099889e-02\n",
      "  8.73616561e-02  7.48155415e-02 -3.18332240e-02  7.09228516e-02\n",
      "  7.61583149e-02  4.37944196e-02  6.64605014e-03  8.74769390e-02\n",
      "  1.05658639e-02 -9.99755859e-02  6.37817383e-02 -3.54546458e-02\n",
      " -1.48179792e-02  9.35058594e-02 -1.15152992e-01 -1.32080078e-01\n",
      "  3.51630300e-02 -4.13682722e-02  4.92587611e-02 -2.36409511e-02\n",
      " -8.00442174e-02  3.93541120e-02  1.24647349e-01  3.15483958e-02\n",
      "  6.87662745e-03 -2.08875872e-02 -1.03444420e-01  1.89141165e-02\n",
      "  4.39724401e-02  6.63113073e-02 -2.57703988e-03  9.86735001e-02\n",
      "  1.63981114e-02 -4.85026054e-02  7.04277903e-02 -6.75184429e-02\n",
      " -1.07591413e-02 -6.74641952e-02 -8.34825337e-02  1.22205950e-02\n",
      "  7.78164342e-02 -8.07427317e-02 -6.07367605e-02  1.02715388e-01\n",
      " -1.53143987e-01 -1.04654945e-01 -3.21180560e-02 -4.63867188e-02\n",
      "  1.15627712e-02 -8.09563498e-05 -3.96728516e-03 -8.68733693e-03\n",
      " -4.24647853e-02 -9.64355469e-02  1.11463755e-01 -8.44828319e-03\n",
      "  2.84288190e-02 -8.08919296e-02  4.95062917e-02 -6.31917343e-02\n",
      "  4.24397774e-02 -1.02764979e-01  4.36740462e-03 -1.08371312e-02\n",
      "  1.71305332e-02  5.84920235e-02  5.80240898e-02 -2.32747402e-02\n",
      "  2.35222708e-02 -4.96961810e-02 -3.28776054e-02  5.96245676e-02\n",
      " -1.53971359e-01 -2.04806849e-02 -9.47265625e-02 -3.73670785e-03\n",
      " -1.73068568e-02  3.02225742e-02 -7.96847865e-02 -2.02365443e-02\n",
      "  4.63595912e-02 -1.25596784e-02 -1.31849498e-01  1.52994795e-02\n",
      " -1.26288518e-01  2.78049037e-02 -5.92380092e-02 -2.09621862e-02\n",
      "  6.83339462e-02 -1.35498047e-02  8.64613876e-02  1.77246094e-01\n",
      "  5.36973737e-02 -5.43484166e-02 -4.06358503e-02  1.44178607e-02\n",
      "  8.62757396e-03  7.26725236e-02 -9.62727889e-02  8.93063005e-03\n",
      "  1.97211374e-02 -2.58924700e-02  1.55768499e-01  8.51779524e-03\n",
      " -1.26627609e-01  5.96245676e-02 -1.30316839e-01  2.98428014e-02\n",
      "  9.70458984e-03 -3.74060720e-02 -1.18164062e-01  4.31586355e-02\n",
      " -5.90277761e-02  5.33311628e-02  9.66661274e-02 -7.50596821e-02\n",
      " -4.63460274e-02 -1.79485753e-02  1.25123128e-01 -3.55902761e-02\n",
      "  6.63248673e-02 -5.78613281e-02 -1.02945961e-01 -2.89984811e-02\n",
      " -2.11859811e-02  3.08566615e-02 -5.99110909e-02  8.70429166e-03\n",
      "  6.41140416e-02 -9.98636857e-02 -4.70784493e-02  9.14577916e-02\n",
      " -8.05799663e-02 -9.98738632e-02 -9.55132395e-02  3.78417969e-03\n",
      " -5.48807764e-03 -1.23765729e-02  5.44704869e-02  5.05540632e-02\n",
      "  6.05875663e-02  4.98860665e-02  5.03743477e-02 -8.46218541e-02\n",
      " -1.17119681e-02  6.20456263e-02 -1.11219622e-02  9.75341797e-02\n",
      " -8.01425502e-02 -7.68534318e-02 -8.83941650e-02  1.99652780e-02\n",
      "  5.29785156e-02 -2.84016933e-02 -6.77908510e-02 -3.85606550e-02\n",
      "  1.70762800e-02  2.40614153e-02  1.60047738e-03  7.26996548e-03\n",
      "  2.10927334e-02  6.40190952e-03 -1.26199082e-01  1.87717006e-02\n",
      " -7.49172643e-02  1.99584961e-02 -5.17578125e-02  5.17272949e-02\n",
      "  6.41716868e-02 -1.07693143e-01 -1.44110784e-01 -3.21112722e-02\n",
      "  1.05794275e-03  4.41894531e-02 -4.15649414e-02 -7.63990581e-02\n",
      "  4.42301445e-02 -6.53754324e-02  1.59261063e-01 -5.17103411e-02\n",
      "  9.48689803e-02 -4.27449532e-02  1.12365723e-01 -5.94075508e-02\n",
      "  7.78537318e-02  3.86394933e-02 -3.88573557e-02  3.03276908e-02\n",
      "  1.66015625e-01 -6.22151680e-02  1.55504018e-01  7.97729492e-02\n",
      "  1.56229660e-01 -4.26974818e-02 -4.65223519e-03 -1.15963832e-01\n",
      "  1.34874135e-01  4.17751726e-03  1.79850254e-02  3.67838554e-02\n",
      "  3.60005684e-02 -4.16937917e-02 -4.71310094e-02  1.00708008e-02\n",
      "  1.92057285e-02  1.07828774e-01  2.06027552e-02 -2.23185215e-02\n",
      " -4.58546728e-02  1.12948949e-02 -1.08778208e-01  1.68728307e-02\n",
      " -5.11338981e-03  6.57755509e-02 -8.25466588e-02 -1.79578997e-02\n",
      "  7.24555105e-02  9.35872365e-03 -7.86471888e-02 -1.54079860e-02\n",
      " -9.13357213e-02  4.18904610e-02  1.88530814e-02  1.49882004e-01\n",
      " -1.98025182e-02  4.34570312e-02  7.97797292e-02 -6.73149973e-02\n",
      " -3.72564532e-02 -5.94075508e-02  2.20913365e-02  1.26836985e-01\n",
      "  1.06852211e-01  2.54024938e-02  6.39105886e-02  1.50994197e-01\n",
      " -1.76323787e-03 -4.34027761e-02 -5.85666224e-02 -4.00119368e-03\n",
      " -2.56347656e-03 -3.20773665e-03 -4.59730364e-02  1.64659284e-02\n",
      " -1.09002009e-01  9.79953334e-02 -5.96788190e-02 -7.86539689e-02\n",
      "  1.88547764e-02  5.78782819e-02 -6.62163645e-02  4.01746966e-02]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mU3hwN53r5un"
   },
   "source": [
    "# Сравнение двух моделей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G-HvrEkHtFqQ"
   },
   "source": [
    "## Загрузка ещё одной модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z13Io-4x3Ve2"
   },
   "source": [
    "\n",
    "Откроем модель google-news-vectors и модель, обученную на британском национальном корпусе http://vectors.nlpl.eu/repository/20/0.zip, с помощью gensim.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0QPYDnlz3X2B",
    "outputId": "5789f370-0e82-4685-ac47-53c537c2d21c",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1687298238685,
     "user_tz": -180,
     "elapsed": 1427439,
     "user": {
      "displayName": "Данила Власов",
      "userId": "10847520665763514044"
     }
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "--2023-06-20 21:33:31--  http://vectors.nlpl.eu/repository/20/0.zip\n",
      "Resolving vectors.nlpl.eu (vectors.nlpl.eu)... 129.240.189.181\n",
      "Connecting to vectors.nlpl.eu (vectors.nlpl.eu)|129.240.189.181|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 344050746 (328M) [application/zip]\n",
      "Saving to: ‘0.zip’\n",
      "\n",
      "0.zip               100%[===================>] 328.11M  7.54MB/s    in 23m 36s \n",
      "\n",
      "2023-06-20 21:57:09 (237 KB/s) - ‘0.zip’ saved [344050746/344050746]\n",
      "\n",
      "Archive:  0.zip\n",
      "  inflating: meta.json               \n",
      "  inflating: model.bin               \n",
      "  inflating: model.txt               \n",
      "  inflating: README                  \n",
      "163473 300\n",
      "say_VERB -0.008861 0.097097 0.100236 0.070044 -0.079279 0.000923 -0.012829 0.064301 -0.029405 -0.009858 -0.017753 0.063115 0.033623 0.019805 0.052704 -0.100458 0.089387 -0.040792 -0.088936 0.110212 -0.044749 0.077675 -0.017062 -0.063745 -0.009502 -0.079371 0.066952 -0.070209 0.063761 -0.038194 -0.046252 0.049983 -0.094985 -0.086341 0.024665 -0.112857 -0.038358 -0.007008 -0.010063 -0.000183 0.068841 0.024942 -0.042561 -0.044576 0.010776 0.006323 0.088285 -0.062522 0.028216 0.088291 0.033231 -0.033732 -0.002995 0.118994 0.000453 0.158588 -0.044475 -0.137629 0.066080 0.062824 -0.128369 -0.087959 0.028080 0.070063 0.046700 -0.083278 -0.118428 0.071118 0.100757 0.017944 0.026296 0.017282 -0.082127 -0.006148 0.002967 -0.032857 -0.076493 -0.072842 -0.055179 -0.081703 0.011437 -0.038698 -0.062540 -0.027899 0.087635 0.031870 0.029164 0.000524 -0.039895 -0.055559 0.024582 -0.030595 0.003942 -0.034500 0.003012 -0.023863 0.033831 0.061476 -0.090183 -0.039206 -0.026586 -0.042763 0.049835 -0.052496 -0.020044 0.073703 0.096775 0.033063 0.000313 -0.022581 -0.141154 0.032095 0.077733 -0.063739 -0.055647 -0.017604 0.044639 -0.062925 -0.001960 0.024665 -0.009416 -0.021381 0.082724 -0.031026 0.027255 0.066198 0.000845 0.008393 0.039434 0.054104 -0.060255 0.034266 0.079435 0.043624 -0.015871 -0.038030 -0.030374 -0.020542 0.007132 0.008708 0.087840 0.017351 -0.089493 0.030182 0.026961 -0.071212 -0.004854 0.007389 0.067203 -0.026351 -0.011460 -0.058723 0.013153 -0.020313 -0.051170 0.002242 0.088222 -0.004267 -0.073523 -0.021874 -0.033585 -0.048553 -0.019119 -0.025310 0.053096 0.111063 0.035042 -0.082811 -0.073749 -0.010048 0.012265 -0.023893 -0.125340 0.026611 0.043258 -0.010473 -0.044428 -0.039251 -0.046891 -0.013008 0.062219 0.078732 -0.086303 0.016901 0.010331 -0.043754 -0.057733 -0.037964 0.024907 0.068143 -0.019992 -0.035030 0.038854 0.034345 -0.048839 -0.105419 0.043013 -0.023374 -0.077629 -0.076465 0.078564 -0.024519 0.041293 -0.032088 -0.007053 0.022618 -0.004657 -0.093970 -0.000199 0.004813 -0.044789 -0.127900 -0.033516 -0.043816 0.033056 -0.057619 0.004901 0.018863 0.039752 0.000739 -0.136350 -0.067819 -0.014856 0.058351 -0.014275 -0.000873 -0.039388 -0.017191 -0.051184 -0.046863 0.006143 -0.075998 -0.064695 0.046676 -0.020558 0.082474 0.160449 -0.027475 0.009541 -0.021876 0.027416 0.078049 0.089309 0.032928 -0.033272 0.048905 0.061164 0.054811 0.024527 -0.034978 -0.018083 -0.077601 0.034112 -0.021121 0.098856 0.019585 -0.058928 -0.016126 -0.011748 0.031588 0.003205 -0.077483 -0.002372 -0.113548 0.047445 -0.027094 -0.032843 0.042378 -0.074703 0.057001 0.012020 0.131156 0.002080 -0.065770 0.112443 0.047786 0.024492 -0.108401 0.016836 0.001478 0.041542 -0.067801 0.102876 -0.052808 -0.136035 0.073852 0.079966 -0.000586 0.034055 -0.053040 0.050461 -0.021550 0.014827 0.077605 -0.024783 -0.082388 0.074410 -0.033689 -0.010982 0.043733\n",
      "go_VERB 0.010490 0.094733 0.143699 0.040344 -0.103710 -0.000016 -0.014351 0.019653 0.069472 -0.046938 -0.057882 0.076405 -0.025230 0.026663 0.029986 -0.001605 -0.027803 0.037521 -0.050608 0.016215 0.025947 0.061172 -0.037448 -0.079232 0.071731 -0.085143 0.021494 -0.135554 -0.026115 -0.066408 0.022858 0.083231 0.020998 -0.049906 -0.079992 -0.060827 -0.028916 -0.029005 0.026067 -0.074869 0.073802 0.023593 -0.024348 -0.093236 0.006169 0.013119 0.007817 -0.088096 -0.012373 0.099807 0.011438 0.028583 0.025614 0.175403 0.007033 0.038856 0.004040 -0.088907 0.079697 0.037448 -0.128230 -0.066502 -0.018969 0.025777 0.035905 0.003710 -0.089079 0.071521 0.039237 0.052136 0.020986 -0.030793 -0.069486 -0.137115 0.008305 0.020813 -0.155342 0.000619 -0.033499 -0.104162 -0.061528 -0.043877 -0.042524 -0.032872 0.045071 0.072908 0.096057 0.141987 -0.078056 -0.013102 -0.026589 -0.073783 0.114807 0.077389 -0.041879 -0.052886 0.053710 0.036806 -0.035973 0.049071 -0.107199 -0.043581 0.016515 -0.029278 -0.026228 0.068037 -0.024183 0.040984 -0.020469 -0.103833 -0.007225 -0.073788 -0.051063 -0.037850 0.052581 -0.053090 -0.012198 -0.057343 0.024050 -0.046498 0.003065 -0.058912 0.043695 0.006340 0.060953 -0.008608 -0.029686 0.081187 -0.020058 0.059240 -0.061306 -0.002190 -0.020671 0.076712 0.049087 0.001153 0.087481 0.008559 0.069936 -0.015886 0.006122 0.038000 -0.071984 0.005263 0.060463 -0.051217 -0.034060 0.045217 0.059163 -0.048462 -0.005371 0.009663 0.081303 0.051019 -0.001248 -0.022637 0.016228 -0.006395 -0.053985 -0.014513 -0.017219 -0.010658 -0.012446 -0.035279 -0.003882 0.036453 0.029681 0.021278 0.006188 0.027861 0.076864 -0.042835 -0.022834 0.013928 0.066150 0.040982 -0.110985 -0.018865 0.006675 0.019173 0.021484 -0.021977 -0.035462 0.000464 -0.024281 0.010881 -0.064037 -0.024893 -0.095968 0.020834 -0.114225 -0.023433 -0.043971 0.014273 0.013481 -0.007542 0.079197 0.021280 -0.129871 0.080770 0.028912 -0.044134 -0.019904 -0.039406 -0.076024 0.058488 -0.094331 -0.082633 0.017676 -0.084006 -0.024444 -0.049778 -0.044615 -0.013499 -0.036736 -0.038579 -0.117319 0.012026 -0.007846 0.024003 -0.101645 0.111720 -0.010241 0.050279 -0.002212 0.060056 -0.116837 0.006078 -0.017954 -0.021794 0.020252 -0.031337 -0.032407 0.081086 -0.095125 0.041699 0.015953 -0.045653 -0.022522 -0.021422 -0.029167 0.052594 0.016523 0.081598 -0.027877 0.000609 0.012837 0.011880 0.074220 0.009736 0.006465 -0.140252 0.010762 -0.038319 0.038924 0.042537 0.005027 0.014024 0.024548 0.050131 -0.048069 -0.012616 -0.052162 -0.100378 0.067741 -0.067824 -0.020692 -0.043022 -0.038036 -0.016860 0.027835 0.140990 -0.045201 -0.069347 0.174518 -0.000236 0.008150 -0.039823 0.041197 0.056322 0.085883 0.027376 0.036537 0.094723 -0.103076 0.105746 0.059074 0.010947 0.099756 -0.027213 0.128793 -0.054593 0.025890 0.053512 0.005200 -0.035256 0.063273 -0.027069 0.046354 -0.002262\n"
     ]
    }
   ],
   "source": [
    "! wget -c http://vectors.nlpl.eu/repository/20/0.zip\n",
    "! unzip 0.zip\n",
    "! head -3 model.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6-21wScRRf1E"
   },
   "source": [
    "Загрузим модель, обученную на британском национальном корпусе"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "-E6OAvhw8-A7",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1687298240666,
     "user_tz": -180,
     "elapsed": 1984,
     "user": {
      "displayName": "Данила Власов",
      "userId": "10847520665763514044"
     }
    }
   },
   "outputs": [],
   "source": [
    "w_british = KeyedVectors.load_word2vec_format(\"model.bin\", binary=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5GpisLDDRf1T"
   },
   "source": [
    "Заметим, что размерность векторов в этом случае также равна 300. При этом через нижнее подчеркивание нужно указывать часть речи используемого слова. Слова следует приводить к нижнему регистру."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "a7VEcvPIRf1W",
    "outputId": "c9028c71-17cb-4454-aec1-b27ae4823068",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1687298240666,
     "user_tz": -180,
     "elapsed": 27,
     "user": {
      "displayName": "Данила Власов",
      "userId": "10847520665763514044"
     }
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(300,)\n",
      "lower is ok\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    print(w_british[\"London_NOUN\"].shape)\n",
    "    print('upper is ok')\n",
    "except:\n",
    "    print(w_british[\"london_NOUN\"].shape)\n",
    "    print('lower is ok')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kfpohw153YQs"
   },
   "source": [
    "## Набор данных для оценки качества\n",
    "Скачаем датасет wordsim353.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b6c2--gQ3bJF",
    "outputId": "eb2c6a33-c658-4144-ae2a-86fd931ff9ee",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1687298241239,
     "user_tz": -180,
     "elapsed": 583,
     "user": {
      "displayName": "Данила Власов",
      "userId": "10847520665763514044"
     }
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "--2023-06-20 21:57:20--  http://alfonseca.org/pubs/ws353simrel.tar.gz\n",
      "Resolving alfonseca.org (alfonseca.org)... 162.215.249.67\n",
      "Connecting to alfonseca.org (alfonseca.org)|162.215.249.67|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 5460 (5.3K) [application/x-gzip]\n",
      "Saving to: ‘ws353simrel.tar.gz’\n",
      "\n",
      "ws353simrel.tar.gz  100%[===================>]   5.33K  --.-KB/s    in 0s      \n",
      "\n",
      "2023-06-20 21:57:20 (684 MB/s) - ‘ws353simrel.tar.gz’ saved [5460/5460]\n",
      "\n",
      "wordsim353_sim_rel/wordsim353_agreed.txt\n",
      "wordsim353_sim_rel/wordsim353_annotator1.txt\n",
      "wordsim353_sim_rel/wordsim353_annotator2.txt\n",
      "wordsim353_sim_rel/wordsim_relatedness_goldstandard.txt\n",
      "wordsim353_sim_rel/wordsim_similarity_goldstandard.txt\n",
      "tiger\tcat\t7.35\n",
      "tiger\ttiger\t10.00\n",
      "plane\tcar\t5.77\n",
      "train\tcar\t6.31\n",
      "television\tradio\t6.77\n"
     ]
    }
   ],
   "source": [
    "! wget -c http://alfonseca.org/pubs/ws353simrel.tar.gz\n",
    "! tar -xvf ws353simrel.tar.gz\n",
    "! head -5 wordsim353_sim_rel/wordsim_similarity_goldstandard.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dgCXUELHRf2E"
   },
   "source": [
    "## Подготовка эталонной выборки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fqy84Dmp3bYa"
   },
   "source": [
    "\n",
    "Из файла `wordsim_similarity_goldstandard.txt` извлечем пары слов и посчитаем косинусное сходство их векторов в обеих моделях. Посчитаем корреляцию оценок сходства в модели google-news-vectors с оценками аннотаторов в датасете, а затем - корреляцию сходства в модели на основе британского национального корпуса с оценками аннотаторов в датасете. Какая модель ближе к суждениям экспертов-разметчиков?\n",
    "\n",
    "(используем только те слова из wordsim, для которых находятся векторы на британском корпусе, помеченные как существительные!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 143
    },
    "id": "Bpeg6FQd3clf",
    "outputId": "ca25f79d-c6cf-41c9-9b37-680e5a3c9d52",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1687298242859,
     "user_tz": -180,
     "elapsed": 1623,
     "user": {
      "displayName": "Данила Власов",
      "userId": "10847520665763514044"
     }
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   first second  score\n",
       "0  tiger    cat   7.35\n",
       "1  tiger  tiger  10.00\n",
       "2  plane    car   5.77"
      ],
      "text/html": [
       "\n",
       "  <div id=\"df-84e26e6c-7221-4767-9091-5a9dc867a8a5\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first</th>\n",
       "      <th>second</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tiger</td>\n",
       "      <td>cat</td>\n",
       "      <td>7.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tiger</td>\n",
       "      <td>tiger</td>\n",
       "      <td>10.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>plane</td>\n",
       "      <td>car</td>\n",
       "      <td>5.77</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-84e26e6c-7221-4767-9091-5a9dc867a8a5')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-84e26e6c-7221-4767-9091-5a9dc867a8a5 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-84e26e6c-7221-4767-9091-5a9dc867a8a5');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"wordsim353_sim_rel/wordsim_similarity_goldstandard.txt\",\n",
    "                 sep=\"\\t\", header=None)\n",
    "df.columns = [\"first\", \"second\", \"score\"]\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rDcXFGZnRf2e"
   },
   "source": [
    "## Вычисление оценок similarity моделей\n",
    "Используем только те слова из wordsim, для которых находятся векторы на британском корпусе, помеченные как существительные, сформируйте 3 массива с оценкам схожести:\n",
    "\n",
    "1. Оценки (косинус между векторами), полученные в результате модели google-news-vectors\n",
    "\n",
    "2. Оценки (косинус между векторами) полученные в результате модели на основе британского национального корпуса\n",
    "\n",
    "3. Эталонные оценки из word_sim, для слов из которых находятся векторы на британском корпусе\n",
    "\n",
    "Пропущенные слова из word_sim представлены в блоке вывода."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qry_vLEd9758",
    "outputId": "72e6f91d-3be4-440b-cc2f-2c9afe6141ff",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1687299682196,
     "user_tz": -180,
     "elapsed": 4,
     "user": {
      "displayName": "Данила Власов",
      "userId": "10847520665763514044"
     }
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\"Key 'stupid_NOUN' not present\" Пропуск данного слова.\n",
      "\"Key 'arafat_NOUN' not present\" Пропуск данного слова.\n",
      "\"Key 'harvard_NOUN' not present\" Пропуск данного слова.\n",
      "\"Key 'mexico_NOUN' not present\" Пропуск данного слова.\n",
      "\"Key 'live_NOUN' not present\" Пропуск данного слова.\n",
      "\"Key 'seven_NOUN' not present\" Пропуск данного слова.\n",
      "\"Key 'five_NOUN' not present\" Пропуск данного слова.\n",
      "\"Key 'mars_NOUN' not present\" Пропуск данного слова.\n"
     ]
    }
   ],
   "source": [
    "gn_dist, br_dist, scores = [], [], []\n",
    "\n",
    "# Вычисление оценок сходства для каждой пары слов\n",
    "for row in df.iterrows():\n",
    "    w1, w2 = row[1][\"first\"], row[1][\"second\"]\n",
    "\n",
    "    try:\n",
    "        gn_similarity = w.similarity(w1, w2)\n",
    "        br_similarity = w_british.similarity(w1.lower() + \"_NOUN\", w2.lower() + \"_NOUN\")\n",
    "\n",
    "        gn_dist.append(gn_similarity)\n",
    "        br_dist.append(br_similarity)\n",
    "        scores.append(row[1][\"score\"])\n",
    "\n",
    "    except KeyError as e:\n",
    "        print(e, \"Пропуск данного слова.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XPyeIR2QtSec"
   },
   "source": [
    "## Выбор модели: корреляция с экспертами\n",
    "\n",
    "Вычислите корреляцию Спирмена для каждой модели по сравнению с эталонными оценками из word_sim.\n",
    "\n",
    "Результаты представлены в блоке вывода."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HZlbnwcq-SCL",
    "outputId": "6cf023ce-8f26-454e-8034-704f22e8d186",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1687299706178,
     "user_tz": -180,
     "elapsed": 464,
     "user": {
      "displayName": "Данила Власов",
      "userId": "10847520665763514044"
     }
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Корреляция Спирмена для Google News модели: 0.7817164245392594\n",
      "Корреляция Спирмена для British National Corpus модели: 0.762755193448961\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import spearmanr\n",
    "\n",
    "# Вычисление корреляции Спирмена между оценками моделей и оценками аннотаторов\n",
    "gn_corr = spearmanr(gn_dist, scores)\n",
    "british_corr = spearmanr(br_dist, scores)\n",
    "\n",
    "print(\"Корреляция Спирмена для Google News модели:\", gn_corr.correlation)\n",
    "print(\"Корреляция Спирмена для British National Corpus модели:\", british_corr.correlation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OtlAncsQANfx"
   },
   "source": [
    "Можно заметить, что модель google-news-vectors несколько выигрывает в данном случае."
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Расчет косинусного расстояния между векторами слов \"professor\" и \"student\" в модели GN\n",
    "gn_distance = w.distance(\"professor\", \"student\")\n",
    "print(\"Результат модели GN:\", gn_distance)\n",
    "\n",
    "# Расчет косинусного расстояния между векторами слов \"professor\" и \"student\" в модели BR\n",
    "br_distance = w_british.distance(\"professor_NOUN\", \"student_NOUN\")\n",
    "print(\"Результат модели BR:\", br_distance)\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RUly3E03588m",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1687299883109,
     "user_tz": -180,
     "elapsed": 3,
     "user": {
      "displayName": "Данила Власов",
      "userId": "10847520665763514044"
     }
    },
    "outputId": "9c2d433d-db5b-411e-82c1-e7e654b91956"
   },
   "execution_count": 24,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Результат модели GN: 0.5793381929397583\n",
      "Результат модели BR: 0.5742734670639038\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Набор слов\n",
    "words = [\"professor\", \"student\", \"smart\", \"wood\"]\n",
    "\n",
    "# Определение лишнего слова с использованием модели GN\n",
    "gn_odd_word = w.doesnt_match(words)\n",
    "print(\"Результат модели GN:\", gn_odd_word)\n",
    "\n",
    "# Определение лишнего слова с использованием модели BR\n",
    "br_odd_word = w_british.doesnt_match([word.lower() + \"_NOUN\" for word in words])\n",
    "print(\"Результат модели BR:\", br_odd_word)\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gtYgpRrw7Cqu",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1687300188118,
     "user_tz": -180,
     "elapsed": 8,
     "user": {
      "displayName": "Данила Власов",
      "userId": "10847520665763514044"
     }
    },
    "outputId": "d22529bd-9cb3-417e-ac9f-2e14e19fee2f"
   },
   "execution_count": 27,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Результат модели GN: wood\n",
      "Результат модели BR: wood_NOUN\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "\n",
    "# Предложения\n",
    "sentence1 = \"fool his money are soon parted\"\n",
    "sentence2 = \"journey thousand miles begins with single step\"\n",
    "\n",
    "# Разделение предложений на отдельные слова\n",
    "words1 = sentence1.split()\n",
    "words2 = sentence2.split()\n",
    "\n",
    "# Нахождение векторов каждого слова в предложениях\n",
    "vectors1 = [w[word] for word in words1 if word in w]\n",
    "vectors2 = [w[word] for word in words2 if word in w]\n",
    "\n",
    "# Усреднение векторов по компонентам\n",
    "avg_vector1 = np.mean(vectors1, axis=0)\n",
    "avg_vector2 = np.mean(vectors2, axis=0)\n",
    "\n",
    "# Расчет косинусного расстояния между векторами предложений\n",
    "gn_distance = np.dot(avg_vector1, avg_vector2) / (np.linalg.norm(avg_vector1) * np.linalg.norm(avg_vector2))\n",
    "\n",
    "print(\"Результат модели GN:\", gn_distance)\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wa1hG7i27idm",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1687300231039,
     "user_tz": -180,
     "elapsed": 493,
     "user": {
      "displayName": "Данила Власов",
      "userId": "10847520665763514044"
     }
    },
    "outputId": "f853d3e2-88d0-44a0-aeac-912abeae49c3"
   },
   "execution_count": 28,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Результат модели GN: 0.3458782\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "\n",
    "sentence1 = \"fool his money are soon parted\"\n",
    "sentence2 = \"journey thousand miles begins with single step\"\n",
    "\n",
    "# Разделение предложений на отдельные слова\n",
    "words1 = sentence1.split()\n",
    "words2 = sentence2.split()\n",
    "\n",
    "# Нахождение векторов для каждого слова в предложениях\n",
    "vectors1 = [w[word.lower()] for word in words1 if word.lower() in w]\n",
    "vectors2 = [w[word.lower()] for word in words2 if word.lower() in w]\n",
    "\n",
    "# Усреднение векторов предложений покомпонентно\n",
    "sentence_vector1 = np.mean(vectors1, axis=0)\n",
    "sentence_vector2 = np.mean(vectors2, axis=0)\n",
    "\n",
    "# Нахождение косинусного расстояния между векторами предложений\n",
    "cosine_distance = np.dot(sentence_vector1, sentence_vector2) / (np.linalg.norm(sentence_vector1) * np.linalg.norm(sentence_vector2))\n",
    "\n",
    "print(\"Результат модели GN:\", cosine_distance)\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xuZykQD48vIH",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1687300568432,
     "user_tz": -180,
     "elapsed": 485,
     "user": {
      "displayName": "Данила Власов",
      "userId": "10847520665763514044"
     }
    },
    "outputId": "b52718da-9c08-4016-ac51-79916f352e1a"
   },
   "execution_count": 31,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Результат модели GN: 0.3458782\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "# Чтение данных из файла word_sim\n",
    "df = pd.read_csv(\"wordsim353_sim_rel/wordsim_similarity_goldstandard.txt\", sep=\"\\t\", header=None)\n",
    "df.columns = [\"first\", \"second\", \"score\"]\n",
    "\n",
    "# Извлечение подвыборки пар слов с индексами 18:118\n",
    "subsample = df.iloc[18:118]\n",
    "\n",
    "# Удаление пар слов, для которых отсутствуют векторы в модели BR или не являются существительными\n",
    "removed_count = 0\n",
    "for index, row in subsample.iterrows():\n",
    "    word1, word2 = row[\"first\"], row[\"second\"]\n",
    "    if word1 + \"_NOUN\" not in w_british or word2 + \"_NOUN\" not in w_british:\n",
    "        subsample = subsample.drop(index)\n",
    "        removed_count += 1\n",
    "\n",
    "# Извлечение оценок сходства и оценок аннотаторов из подвыборки\n",
    "scores = subsample[\"score\"]\n",
    "model_scores_gn = []\n",
    "model_scores_br = []\n",
    "\n",
    "# Расчет оценок сходства для моделей GN и BR\n",
    "for index, row in subsample.iterrows():\n",
    "    word1, word2 = row[\"first\"], row[\"second\"]\n",
    "    similarity_gn = w.similarity(word1, word2)\n",
    "    similarity_br = w_british.similarity(word1 + \"_NOUN\", word2 + \"_NOUN\")\n",
    "    model_scores_gn.append(similarity_gn)\n",
    "    model_scores_br.append(similarity_br)\n",
    "\n",
    "# Расчет коэффициента корреляции Спирмена для моделей GN и BR\n",
    "gn_corr = spearmanr(model_scores_gn, scores).correlation\n",
    "br_corr = spearmanr(model_scores_br, scores).correlation\n",
    "\n",
    "print(\"Коэффициент корреляции спирмена для модели GN:\", round(gn_corr, 3))\n",
    "print(\"Коэффициент корреляции спирмена для модели BR:\", round(br_corr, 3))\n",
    "print(\"Количество удаленных из подвыборки пар слов:\", removed_count)\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DOAZW-QP8H2d",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1687300377646,
     "user_tz": -180,
     "elapsed": 479,
     "user": {
      "displayName": "Данила Власов",
      "userId": "10847520665763514044"
     }
    },
    "outputId": "31bcbda9-27a5-4078-b8fe-ed167e1a9ed5"
   },
   "execution_count": 29,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Коэффициент корреляции спирмена для модели GN: 0.721\n",
      "Коэффициент корреляции спирмена для модели BR: 0.684\n",
      "Количество удаленных из подвыборки пар слов: 4\n"
     ]
    }
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
